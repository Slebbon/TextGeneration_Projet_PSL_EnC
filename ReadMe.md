# Shrump 
Finetuning of different large language models on a mixed dataset of Shakespeare quotes and Trump tweets

## Content

- `Dataset`: code and data used to create the final datasets

    - `finetuning_dataset`: final dataset used to finetune the models

    - `integrated_dataset`: dataset used to train the BERT classifier for performance evaluation

- `Finetuning_notebooks`: notebooks used to finetune the three models

- `performance_evaluation`: code used to finetune the BERT classifier and code used to evaluate the performance of the models through the classifier